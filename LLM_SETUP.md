# 🤖 הוספת אנושיות לבוט עם Ollama

הבוט כעת תומך בשימוש ב-Ollama כדי להפוך את ההודעות ליותר אנושיות, חמות ומגוונות.

## 📋 הכנה

### 1. התקנת Ollama
אם עדיין לא התקנת את Ollama, הורידי אותו מ:
https://ollama.com/download

### 2. התקנת מודל
לאחר ההתקנה, פתחי טרמינל והריצי:
```bash
ollama pull llama3.2:3b
```

או מודל אחר לבחירתך:
- `mistral` - מודל מהיר וטוב
- `gemma2:2b` - מודל קטן ומהיר מאוד
- `llama3.2:1b` - הכי קטן ומהיר

### 3. הפעלת Ollama
Ollama צריך לרוץ ברקע. אם הוא לא רץ, הריצי:
```bash
ollama serve
```

## ⚙️ הגדרות

בקובץ `.env` שלך, הוסיפי (אופציונלי):

```env
# LLM Configuration
USE_LLM=true                    # true = להשתמש ב-LLM, false = הודעות רגילות
LLM_MODEL=llama3.2:3b          # שם המודל שהתקנת
```

ברירות מחדל:
- `USE_LLM=true` - ה-LLM מופעל כברירת מחדל
- `LLM_MODEL=llama3.2:3b` - מודל ברירת מחדל

## 🧪 בדיקה

לבדוק שהכל עובד, הריצי:
```bash
python test_llm.py
```

זה יבדוק את החיבור ל-Ollama ויראה לך דוגמאות של הודעות אנושיות.

## 🎯 איך זה עובד?

הבוט מאנוש את ההודעות במקומות הבאים:

### 1. הודעות מתוזמנות (11:00, 14:00, 17:00)
במקום:
```
בוקר טוב 🙂
צ׳ק־אין קצר:
עבדת היום?
```

תקבלי משהו כמו:
```
היי! בוקר טוב ☀️
בואי נעשה צ׳ק-אין מהיר -
איך היום? עבדת על משהו?
```

### 2. התזכורות (Nudges)
במקום:
```
עבר הזמן שקבענו (10 דקות) 🙂
רוצה לסמן לי אם התקדמת?
```

תקבלי משהו כמו:
```
עברו 10 דקות 😊
איך זה הלך? הצלחת להתקדם?
```

## 🎨 התאמה אישית

אם רוצה להוסיף אנושיות למקומות נוספים בבוט:

```python
from hilanchor.llm import humanize_message

# דוגמה:
original = "אלופה ✅\nמה עשית? (משפט)"
humanized = humanize_message(original, context="user completed task")
```

## 💡 טיפים

1. **ביצועים**: מודלים קטנים יותר (1b-3b) מהירים ומספיקים לטקסטים קצרים
2. **וריאציה**: כל פעם תקבלי הודעה שונה במקצת - זה מה שעושה את זה אנושי!
3. **כיבוי**: אם רוצה לכבות את התכונה, שני `USE_LLM=false` ב-`.env`

## 🔧 פתרון בעיות

### הבוט לא מגיב / תקוע
1. בדקי ש-Ollama רץ: `ollama list`
2. בדקי שהמודל מותקן: `ollama list` צריך להראות את המודל שלך
3. הריצי `python test_llm.py` לבדיקה

### הודעות לוקחות זמן
- זה נורמלי בפעם הראשונה (המודל נטען לזיכרון)
- שקלי מודל קטן יותר אם זה לוקח יותר מדי זמן
- או כבי את התכונה: `USE_LLM=false`

### הודעות לא בעברית
- תבדקי שהמודל תומך בעברית טוב
- `llama3.2` ו-`mistral` עובדים טוב עם עברית
